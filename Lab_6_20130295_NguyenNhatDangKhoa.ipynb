{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nguyennhatdangkhoa20130295/ML_Thu3_Ca4/blob/main/Lab_6_20130295_NguyenNhatDangKhoa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with classification task using **Random Forests** and **Na√Øve Bayes** algorithms with/without **Feature Selection**. \n",
        "\n",
        "*   **Deadline: 23:59, 25/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85c4a1b-950a-4ffe-ac66-8b4224be3df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/ML\n"
          ]
        }
      ],
      "source": [
        "# code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, CategoricalNB, BernoulliNB, MultinomialNB, ComplementNB\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "metadata": {
        "id": "wrRWWm8OyguY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Task 1. Compare the performance of selected classification algorithms including **Random forest**, **NaiveBayes**, and **SVM** with **mnist** dataset based on **accuracy, precision, recall, f1** measures according to **without using selection feature** and **using selection feature**.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# without using selection feature\n",
        "data = datasets.load_digits()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
        "svm_model = SVC(kernel ='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "\n",
        "svm_acc = accuracy_score(y_test, y_pred)\n",
        "svm_prec = precision_score(y_test, y_pred, average = 'macro')\n",
        "svm_recall = recall_score(y_test, y_pred, average = 'macro')\n",
        "svm_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
        "\n",
        "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
        "rfc_prec = precision_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_recall = recall_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_f1 = f1_score(y_test, rfc_pred, average = 'macro')\n",
        "\n",
        "g_acc = accuracy_score(y_test, gnb_pred)\n",
        "g_prec = precision_score(y_test, gnb_pred, average = 'macro')\n",
        "g_recall = recall_score(y_test, gnb_pred, average = 'macro')\n",
        "g_f1 = f1_score(y_test, gnb_pred, average = 'macro')\n",
        "\n",
        "t = PrettyTable(['Algorithm','Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row([\"SVM\", round(svm_acc, 2), round(svm_prec, 2), round(svm_recall, 2), round(svm_f1, 2)])\n",
        "t.add_row([\"Random forest\", round(rfc_acc, 2), round(rfc_prec, 2), round(rfc_recall, 2), round(rfc_f1, 2)])\n",
        "t.add_row([\"Naivebayes\", round(g_acc, 2), round(g_prec, 2), round(g_recall, 2), round(g_f1, 2)])\n",
        "\n",
        "print(t)\n",
        "\n"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1b539e-23ff-43cf-f926-d871bfa2a589"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.98   |    0.97   |  0.97  | 0.97 |\n",
            "| Random forest |   0.99   |    0.99   |  0.99  | 0.99 |\n",
            "|   Naivebayes  |   0.89   |    0.9    |  0.88  | 0.88 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "# with using selection feature\n",
        "X_new = SelectKBest(chi2, k='all').fit_transform(X, y)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=20)\n",
        "svm_model = SVC(kernel ='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "\n",
        "svm_acc = accuracy_score(y_test, y_pred)\n",
        "svm_prec = precision_score(y_test, y_pred, average = 'macro')\n",
        "svm_recall = recall_score(y_test, y_pred, average = 'macro')\n",
        "svm_f1 = f1_score(y_test, y_pred, average = 'macro')\n",
        "\n",
        "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
        "rfc_prec = precision_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_recall = recall_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_f1 = f1_score(y_test, rfc_pred, average = 'macro')\n",
        "\n",
        "g_acc = accuracy_score(y_test, gnb_pred)\n",
        "g_prec = precision_score(y_test, gnb_pred, average = 'macro')\n",
        "g_recall = recall_score(y_test, gnb_pred, average = 'macro')\n",
        "g_f1 = f1_score(y_test, gnb_pred, average = 'macro')\n",
        "\n",
        "t = PrettyTable(['Algorithm','Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row([\"SVM\", round(svm_acc, 2), round(svm_prec, 2), round(svm_recall, 2), round(svm_f1, 2)])\n",
        "t.add_row([\"Random forest\", round(rfc_acc, 2), round(rfc_prec, 2), round(rfc_recall, 2), round(rfc_f1, 2)])\n",
        "t.add_row([\"Naivebayes\", round(g_acc, 2), round(g_prec, 2), round(g_recall, 2), round(g_f1, 2)])\n",
        "\n",
        "print(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrFrR3gS4yFZ",
        "outputId": "bc338778-1124-436a-e417-3790ae0a4bf8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "|      SVM      |   0.98   |    0.97   |  0.97  | 0.97 |\n",
            "| Random forest |   0.99   |    0.99   |  0.99  | 0.99 |\n",
            "|   Naivebayes  |   0.89   |    0.9    |  0.88  | 0.88 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "For given bank dataset (bank.csv) having the following attributes :\n",
        "1.\t**age** (numeric)\n",
        "2.\t**job** : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
        "3.\t**marital** : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
        "4.\t**education** (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
        "5.\t**default**: has credit in default? (categorical: 'no','yes','unknown')\n",
        "6.\t**housing**: has housing loan? (categorical: 'no','yes','unknown')\n",
        "7.\t**loan**: has personal loan? (categorical: 'no','yes','unknown')\n",
        "8.\t**contact**: contact communication type (categorical: 'cellular','telephone')\n",
        "9.\t**month**: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
        "10.\t**day_of_week**: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
        "11.\t**duration**: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
        "12.\t**campaign**: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
        "13.\t**pdays**: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
        "14.\t**previous**: number of contacts performed before this campaign and for this client (numeric)\n",
        "15.\t**poutcome**: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
        "Output variable (desired target):\n",
        "16.\t**y**. has the client subscribed a term deposit? (binary: 'yes','no')\n",
        "\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X0Shzk1eALGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.1. Apply StandardScaler() function to columns that contains numerical data ('age', 'balance', 'day', 'campaign', 'pdays', 'previous')"
      ],
      "metadata": {
        "id": "q89LEvT7dqaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "dataset = pd.read_csv(\"bank.csv\");\n",
        "scaler = StandardScaler()\n",
        "dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']] = scaler.fit_transform(dataset[['age', 'balance', 'day', 'campaign', 'pdays', 'previous']])"
      ],
      "metadata": {
        "id": "8vx3mfIidu4P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.2. Apply Encode Categorical Value (OneHotEncoder) to transfrom categorical data to numerical data ('job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome')"
      ],
      "metadata": {
        "id": "r7acR0TxdvY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "encoder = OneHotEncoder()\n",
        "column_title = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
        "encoded_column = encoder.fit_transform(dataset[column_title]).toarray()\n",
        "encoded_new_data = pd.DataFrame(encoded_column, columns=encoder.get_feature_names_out(column_title))\n",
        "new_dataset = pd.concat([dataset.drop(column_title, axis=1), encoded_new_data], axis=1)"
      ],
      "metadata": {
        "id": "egtgBmAtd0um"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.3. Apply **Decision tree, Random forest, kNN, Na√ØveBayes** to preproceed dataset in the previous steps. Then compare the obtained results using **accuracy, precision, recall, f1** measures."
      ],
      "metadata": {
        "id": "K2Si6d69d1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "X = new_dataset.drop('deposit', axis=1)\n",
        "y = new_dataset['deposit']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train)\n",
        "dt_pred = dt.predict(X_test)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "knn_pred = knn.predict(X_test)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_test)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "gnb_pred = gnb.predict(X_test)\n",
        "\n",
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "dt_prec = precision_score(y_test, dt_pred, average='macro')\n",
        "dt_recall = recall_score(y_test, dt_pred, average='macro')\n",
        "dt_f1 = f1_score(y_test, dt_pred, average='macro')\n",
        "\n",
        "knn_acc = accuracy_score(y_test, knn_pred)\n",
        "knn_prec = precision_score(y_test, knn_pred, average='macro')\n",
        "knn_recall = recall_score(y_test, knn_pred, average='macro')\n",
        "knn_f1 = f1_score(y_test, knn_pred, average='macro')\n",
        "\n",
        "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
        "rfc_prec = precision_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_recall = recall_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_f1 = f1_score(y_test, rfc_pred, average = 'macro')\n",
        "\n",
        "g_acc = accuracy_score(y_test, gnb_pred)\n",
        "g_prec = precision_score(y_test, gnb_pred, average = 'macro')\n",
        "g_recall = recall_score(y_test, gnb_pred, average = 'macro')\n",
        "g_f1 = f1_score(y_test, gnb_pred, average = 'macro')\n",
        "\n",
        "t = PrettyTable(['Algorithm','Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row([\"Decision tree\", round(dt_acc, 2), round(dt_prec, 2), round(dt_recall, 2), round(dt_f1, 2)])\n",
        "t.add_row([\"kNN\", round(knn_acc, 2), round(knn_prec, 2), round(knn_recall, 2), round(knn_f1, 2)])\n",
        "t.add_row([\"Random forest\", round(rfc_acc, 2), round(rfc_prec, 2), round(rfc_recall, 2), round(rfc_f1, 2)])\n",
        "t.add_row([\"Naivebayes\", round(g_acc, 2), round(g_prec, 2), round(g_recall, 2), round(g_f1, 2)])\n",
        "\n",
        "print(t)"
      ],
      "metadata": {
        "id": "Ouil-cf_d8jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c95321-6b8d-42a0-e022-578f89b76d7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+----------+-----------+--------+------+\n",
            "|   Algorithm   | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------+----------+-----------+--------+------+\n",
            "| Decision tree |   0.79   |    0.79   |  0.79  | 0.79 |\n",
            "|      kNN      |   0.77   |    0.77   |  0.77  | 0.77 |\n",
            "| Random forest |   0.85   |    0.85   |  0.85  | 0.85 |\n",
            "|   Naivebayes  |   0.72   |    0.74   |  0.72  | 0.72 |\n",
            "+---------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.4. Using selection feature to above dataset, then compare the classification results with those in Task 2.3. "
      ],
      "metadata": {
        "id": "SweVRB4meApP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code\n",
        "\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "svm_model = SVC(kernel ='linear')\n",
        "svm_model.fit(X_train_selected, y_train)\n",
        "svm_pred = svm_model.predict(X_test_selected)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_selected, y_train)\n",
        "lr_pred = lr.predict(X_test_selected)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_selected, y_train)\n",
        "dt_pred = dt.predict(X_test_selected)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_selected, y_train)\n",
        "knn_pred = knn.predict(X_test_selected)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train_selected, y_train)\n",
        "rfc_pred = rfc.predict(X_test_selected)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_selected, y_train)\n",
        "gnb_pred = gnb.predict(X_test_selected)\n",
        "\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "svm_prec = precision_score(y_test, svm_pred, average='macro')\n",
        "svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
        "svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
        "\n",
        "lr_acc = accuracy_score(y_test, lr_pred)\n",
        "lr_prec = precision_score(y_test, lr_pred, average='macro')\n",
        "lr_recall = recall_score(y_test, lr_pred, average='macro')\n",
        "lr_f1 = f1_score(y_test, lr_pred, average='macro')\n",
        "\n",
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "dt_prec = precision_score(y_test, dt_pred, average='macro')\n",
        "dt_recall = recall_score(y_test, dt_pred, average='macro')\n",
        "dt_f1 = f1_score(y_test, dt_pred, average='macro')\n",
        "\n",
        "knn_acc = accuracy_score(y_test, knn_pred)\n",
        "knn_prec = precision_score(y_test, knn_pred, average='macro')\n",
        "knn_recall = recall_score(y_test, knn_pred, average='macro')\n",
        "knn_f1 = f1_score(y_test, knn_pred, average='macro')\n",
        "\n",
        "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
        "rfc_prec = precision_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_recall = recall_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_f1 = f1_score(y_test, rfc_pred, average = 'macro')\n",
        "\n",
        "g_acc = accuracy_score(y_test, gnb_pred)\n",
        "g_prec = precision_score(y_test, gnb_pred, average = 'macro')\n",
        "g_recall = recall_score(y_test, gnb_pred, average = 'macro')\n",
        "g_f1 = f1_score(y_test, gnb_pred, average = 'macro')\n",
        "\n",
        "t = PrettyTable(['Algorithm','Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row([\"SVM\", round(svm_acc, 2), round(svm_prec, 2), round(svm_recall, 2), round(svm_f1, 2)])\n",
        "t.add_row([\"Decision tree\", round(dt_acc, 2), round(dt_prec, 2), round(dt_recall, 2), round(dt_f1, 2)])\n",
        "t.add_row([\"kNN\", round(knn_acc, 2), round(knn_prec, 2), round(knn_recall, 2), round(knn_f1, 2)])\n",
        "t.add_row([\"Logistic Regression\", round(lr_acc, 2), round(lr_prec, 2), round(lr_recall, 2), round(lr_f1, 2)])\n",
        "t.add_row([\"Random forest\", round(rfc_acc, 2), round(rfc_prec, 2), round(rfc_recall, 2), round(rfc_f1, 2)])\n",
        "t.add_row([\"Naivebayes\", round(g_acc, 2), round(g_prec, 2), round(g_recall, 2), round(g_f1, 2)])\n",
        "\n",
        "print(t)"
      ],
      "metadata": {
        "id": "seFBhqCSeC7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f1aad2-577b-4a26-e1f3-c864f959d674"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+----------+-----------+--------+------+\n",
            "|      Algorithm      | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------------+----------+-----------+--------+------+\n",
            "|         SVM         |   0.8    |    0.8    |  0.8   | 0.8  |\n",
            "|    Decision tree    |   0.73   |    0.73   |  0.73  | 0.73 |\n",
            "|         kNN         |   0.76   |    0.76   |  0.76  | 0.76 |\n",
            "| Logistic Regression |   0.79   |    0.79   |  0.79  | 0.79 |\n",
            "|    Random forest    |   0.75   |    0.75   |  0.75  | 0.75 |\n",
            "|      Naivebayes     |   0.71   |    0.71   |  0.7   | 0.7  |\n",
            "+---------------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "For a given dataset in the Lab #5 (**credit card dataset**), perform feature selection and thencompare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression, SVM, Random Forest and NaiveBayes) based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "data = pd.read_csv(\"creditcard.csv\")\n",
        "X = data.drop('Class', axis=1)\n",
        "y = data['Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "selector = SelectKBest(f_classif, k=10)\n",
        "selector.fit(X_train, y_train)\n",
        "\n",
        "X_train_selected = selector.transform(X_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "svm_model = SVC(kernel ='linear')\n",
        "svm_model.fit(X_train_selected, y_train)\n",
        "svm_pred = svm_model.predict(X_test_selected)\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_selected, y_train)\n",
        "lr_pred = lr.predict(X_test_selected)\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train_selected, y_train)\n",
        "dt_pred = dt.predict(X_test_selected)\n",
        "\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_selected, y_train)\n",
        "knn_pred = knn.predict(X_test_selected)\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=100)\n",
        "rfc.fit(X_train_selected, y_train)\n",
        "rfc_pred = rfc.predict(X_test_selected)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_selected, y_train)\n",
        "gnb_pred = gnb.predict(X_test_selected)\n",
        "\n",
        "svm_acc = accuracy_score(y_test, svm_pred)\n",
        "svm_prec = precision_score(y_test, svm_pred, average='macro')\n",
        "svm_recall = recall_score(y_test, svm_pred, average='macro')\n",
        "svm_f1 = f1_score(y_test, svm_pred, average='macro')\n",
        "\n",
        "lr_acc = accuracy_score(y_test, lr_pred)\n",
        "lr_prec = precision_score(y_test, lr_pred, average='macro')\n",
        "lr_recall = recall_score(y_test, lr_pred, average='macro')\n",
        "lr_f1 = f1_score(y_test, lr_pred, average='macro')\n",
        "\n",
        "dt_acc = accuracy_score(y_test, dt_pred)\n",
        "dt_prec = precision_score(y_test, dt_pred, average='macro')\n",
        "dt_recall = recall_score(y_test, dt_pred, average='macro')\n",
        "dt_f1 = f1_score(y_test, dt_pred, average='macro')\n",
        "\n",
        "knn_acc = accuracy_score(y_test, knn_pred)\n",
        "knn_prec = precision_score(y_test, knn_pred, average='macro')\n",
        "knn_recall = recall_score(y_test, knn_pred, average='macro')\n",
        "knn_f1 = f1_score(y_test, knn_pred, average='macro')\n",
        "\n",
        "rfc_acc = accuracy_score(y_test, rfc_pred)\n",
        "rfc_prec = precision_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_recall = recall_score(y_test, rfc_pred, average = 'macro')\n",
        "rfc_f1 = f1_score(y_test, rfc_pred, average = 'macro')\n",
        "\n",
        "g_acc = accuracy_score(y_test, gnb_pred)\n",
        "g_prec = precision_score(y_test, gnb_pred, average = 'macro')\n",
        "g_recall = recall_score(y_test, gnb_pred, average = 'macro')\n",
        "g_f1 = f1_score(y_test, gnb_pred, average = 'macro')\n",
        "\n",
        "t = PrettyTable(['Algorithm','Accuracy', 'Precision', 'Recall', 'F1'])\n",
        "t.add_row([\"SVM\", round(svm_acc, 2), round(svm_prec, 2), round(svm_recall, 2), round(svm_f1, 2)])\n",
        "t.add_row([\"Decision tree\", round(dt_acc, 2), round(dt_prec, 2), round(dt_recall, 2), round(dt_f1, 2)])\n",
        "t.add_row([\"kNN\", round(knn_acc, 2), round(knn_prec, 2), round(knn_recall, 2), round(knn_f1, 2)])\n",
        "t.add_row([\"Logistic Regression\", round(lr_acc, 2), round(lr_prec, 2), round(lr_recall, 2), round(lr_f1, 2)])\n",
        "t.add_row([\"Random forest\", round(rfc_acc, 2), round(rfc_prec, 2), round(rfc_recall, 2), round(rfc_f1, 2)])\n",
        "t.add_row([\"Naivebayes\", round(g_acc, 2), round(g_prec, 2), round(g_recall, 2), round(g_f1, 2)])\n",
        "\n",
        "print(t)"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7fe203c-48c8-44fa-db9e-8cc278e05673"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+----------+-----------+--------+------+\n",
            "|      Algorithm      | Accuracy | Precision | Recall |  F1  |\n",
            "+---------------------+----------+-----------+--------+------+\n",
            "|         SVM         |   1.0    |    0.92   |  0.9   | 0.91 |\n",
            "|    Decision tree    |   1.0    |    0.84   |  0.88  | 0.86 |\n",
            "|         kNN         |   1.0    |    0.95   |  0.92  | 0.94 |\n",
            "| Logistic Regression |   1.0    |    0.93   |  0.81  | 0.86 |\n",
            "|    Random forest    |   1.0    |    0.97   |  0.92  | 0.94 |\n",
            "|      Naivebayes     |   0.99   |    0.57   |  0.94  | 0.61 |\n",
            "+---------------------+----------+-----------+--------+------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}